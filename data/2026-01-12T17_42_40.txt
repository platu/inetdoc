TITLE: Enseignements Ops à l'ère du déclaratif : entre progrès et dérives
AUTHOR: Philippe Latu
DATE: lun. 12 janv. 2026 17:42:40 CET
DESC: Les configurations déclaratives YAML et de cloud-init transforme radicalement l'apprentissage de l'administration système.
FORMAT: raw
-----
BODY:
<p>Après avoir migré la gestion des machines virtuelles vers un mode déclaratif
basé sur des fichiers YAML (<a
href="https://gitlab.inetdoc.net/labs/startup-scripts/-/blob/main/lab-startup.py?ref_type=heads">lab-startup.py</a>),
j'ai ajouté l'utilisation de <a href="https://cloud-init.io/">Cloud-init</a> en septembre dernier.</p>

<p>La dernière révision du support de travaux pratiques <strong>&laquo;&nbsp;<a
href="https://md.inetdoc.net/s/zL2STyrLf6">Start unprivileged Incus containers
on top of Open vSwitch in a few steps</a>&nbsp;&raquo;</strong> illustre bien cette
évolution.</p>

<p>Les travaux pratiques ont beaucoup gagné en reproductibilité. Cette
évolution met toutefois en lumière un écart croissant entre les étudiants qui
structurent mieux leurs actions et ceux qui se contentent de copier-coller des
configurations sans comprendre les opérations d'administration système
attendues.</p>

<h4>Le paradoxe de l'abstraction déclarative</h4>

<p>Cette approche marque une rupture avec les pratiques impératives classiques.
Auparavant, chaque commande était exécutée en observant son effet ;
aujourd'hui, les fichiers YAML décrivent un état cible sans détailler les
étapes. Cette abstraction constitue un véritable progrès pour
l'industrialisation et la reproductibilité.</p>

<p>Sur le plan pédagogique, elle crée toutefois un piège. Les étudiants les
plus investis l'utilisent pour mieux structurer le séquencement des opérations.
D’autres transforment les salons Discord en &laquo;&nbsp;marketplaces
YAML&nbsp;&raquo; et récupèrent des configurations toutes faites, au détriment
de l'objectif central, à savoir analyser un problème, choisir les actions
nécessaires et construire une solution cohérente.</p>

<h4>L'IA conversationnelle&nbsp;: un faux ami pédagogique</h4>

<p>L'utilisation d'agents conversationnels tels que ChatGPT amplifie cette
dérive. La consultation des logs des hyperviseurs révèle des tentatives
d'exécution de commandes incohérentes, totalement déconnectées des énoncés des
travaux pratiques. Le problème n'est pas que les étudiants commettent des
erreurs — l'erreur fait pleinement partie de l'apprentissage —, mais qu'ils
exécutent des instructions sans rapport avec le contexte pédagogique, ce qui
témoigne d'une absence totale d'attention et de réflexion.</p>

<p>Au lieu d'utiliser l'IA comme assistant pour approfondir leur compréhension,
une minorité d'étudiants la sollicitent sans aucune contextualisation. Ils
obtiennent ainsi des réponses génériques (j'ai envie d'écrire
&laquo;&nbsp;hallucinées&nbsp;&raquo;) qui ne correspondent ni à
l'environnement de formation ni aux objectifs pédagogiques. L'IA devient alors
un obstacle à l'apprentissage en créant une &laquo;&nbsp;illusion de
maîtrise&nbsp;&raquo;.</p>

<h4>Le contexte formation initiale ne facilite pas les choses</h4>

<p>Les ressources documentaires sont largement accessibles en ligne, et les
solutions aux exercices pratiques sont disponibles publiquement. Cette
accessibilité, combinée à la facilité d'interroger des agents conversationnels,
supprime toute incitation à fournir un effort de contextualisation et de
sélection précise des sources.</p>

<p>À mon humble niveau de compétences, je n'avais jamais eu à insister autant
sur la sélection des documents et la validation de l'applicabilité d'une
solution à un contexte donné. Je sens également le manque de ma formation aux
méthodologies de recherche assistée par IA, notamment aux techniques de RAG
(<i>Retrieval Augmented Generation</i>), qui permettent d'ancrer les réponses
de l'IA dans des corpus documentaires spécifiques. C'est un point sur lequel je
dois travailler lors des prochains modules.</p>

END-----
