<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook V5.0/EN"
    "/usr/share/xml/docbook/schema/dtd/5.0/docbook.dtd" [

<!ENTITY author       SYSTEM "author.xml">
<!ENTITY legal        SYSTEM "legal.xml">

<!ENTITY % inetdoc_urls SYSTEM 'inetdoc.urls.ent'>
%inetdoc_urls;

<!ENTITY url.startup-scripts
    '<link xmlns="http://docbook.org/ns/docbook"
     xmlns:xlink="http://www.w3.org/1999/xlink"
     xlink:href="https://gitlab.inetdoc.net/labs/startup-scripts"><citetitle>startup-scripts</citetitle></link>'>

<!ENTITY url.netplan-doc
    '<link xmlns="http://docbook.org/ns/docbook"
     xmlns:xlink="http://www.w3.org/1999/xlink"
     xlink:href="https://netplan.readthedocs.io/en/stable/"><citetitle>Netplan
     documentation</citetitle></link>'>

<!ENTITY url.incus
    '<link xmlns="http://docbook.org/ns/docbook"
     xmlns:xlink="http://www.w3.org/1999/xlink"
     xlink:href="https://linuxcontainers.org/incus/docs/main/"><citetitle>Incus</citetitle></link>'>

<!ENTITY url.macvlan
    '<link xmlns="http://docbook.org/ns/docbook"
     xmlns:xlink="http://www.w3.org/1999/xlink"
     xlink:href="https://developers.redhat.com/blog/2018/10/22/introduction-to-linux-interfaces-for-virtual-networking#macvlan"><citetitle>macvlan</citetitle></link>'>

<!-- A copy of http://www.w3.org/2003/entities/2007/w3centities-f.ent is at:
  /usr/local/share -->
<!ENTITY % w3centities-f PUBLIC "-//W3C//ENTITIES Combined Set//EN//XML"
    "/usr/local/share/w3centities-f.ent">
%w3centities-f;
]>

<article xmlns="http://docbook.org/ns/docbook" version="5.0"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    xml:id="inter-vlan-iaas" xml:lang="fr">

<info>
    <title>Routage inter-VLAN dans un contexte IaaS</title>
    &author;
<abstract>
<para>
    <informaltable frame='none' pgwide='1'>
    <tgroup cols='2' align='left' colsep='0' rowsep='0'>
    <colspec colwidth='5*'/>
    <colspec colwidth='220px'/>
    <tbody>
    <row>
        <entry valign='top'>
        <para>Ce support de travaux pratiques détaille la mise en œuvre du
        routage inter-VLAN dans une infrastructure IaaS avec deux machines
        virtuelles, dont l'une héberge des conteneurs
        <application>Incus</application>. Il guide l'utilisateur pas à pas dans
        la configuration d'un réseau comportant plusieurs VLAN. Il commence par
        montrer comment connecter les deux machines virtuelles via un
        commutateur de distribution <application>Open vSwitch</application>,
        puis comment mettre en place le routage entre les réseaux de
        l'hyperviseur et les réseaux de conteneurs utilisant la technologie
        &url.macvlan;.</para>

        <para>Le document couvre l'ensemble du cycle&nbsp;: configuration du
        réseau (IPv4/IPv6) et du routage sur GNU/Linux, activation de la
        traduction d'adresses (NAT avec nftables), gestion de l'adressage
        automatique (dnsmasq), installation et le paramétrage du gestionnaire
        de conteneurs <application>Incus</application>, ainsi que
        l'automatisation de tâches courantes avec des scripts
        <application>Bash</application>.</para>
        </entry>
        <entry>
        <inlinemediaobject>
        <imageobject role='html'>
            <imagedata fileref='images/inter-VLAN-logical-topology.png' format='PNG' width='360px' scalefit='1'/>
        </imageobject>
        <imageobject role='fo'>
            <imagedata fileref='images/inter-VLAN-logical-topology.png' format='PNG' width='6cm' scalefit='1'/>
        </imageobject>
        </inlinemediaobject>
        </entry>
    </row>
    </tbody>
    </tgroup>
    </informaltable>
</para>
</abstract>
<keywordset>
    <keyword>8021q</keyword>
    <keyword>access</keyword>
    <keyword>arp</keyword>
    <keyword>dot1q</keyword>
    <keyword>iproute2</keyword>
    <keyword>nftables</keyword>
    <keyword>incus</keyword>
    <keyword>macvlan</keyword>
    <keyword>route</keyword>
    <keyword>routing</keyword>
    <keyword>sysctl</keyword>
    <keyword>trunk</keyword>
</keywordset>
</info>

<sect1 xml:id='inter-vlan-iaas.meta'>
    &legal;
    <bridgehead xml:id='sysadm-net.inter-vlan.meta.file'
    renderas='sect2'>Méta-information</bridgehead>

    <para>Ce document est écrit avec <link
    xlink:href="http://www.docbook.org"><citetitle>DocBook</citetitle></link>
    XML sur un système <link
    xlink:href="https://www.debian.org"><citetitle>Debian
    GNU/Linux</citetitle></link>. Il est disponible en version imprimable au
    format PDF&nbsp;: <link
    xlink:href="https://www.inetdoc.net/pdf/__printbasename__"><literal>__printbasename__</literal></link>.</para>
</sect1>

<?custom-pagebreak?>
<sect1 xml:id='inter-vlan-iaas.objectives'>
	<title>Objectifs</title>

    <para>Après avoir réalisé les manipulations présentées dans ce document,
    les étudiants seront capables de&nbsp;:</para>

    <orderedlist>
    <listitem>
    <para>Configurer le routage inter-VLAN sur un système GNU/Linux avec
    l'activation du routage et la configuration des interfaces réseau.</para>
    </listitem>
    <listitem>
    <para>Mettre en place et configurer un service de traduction d'adresses
    (<acronym>NAT</acronym>) pour permettre aux réseaux internes d'accéder à
    Internet.</para>
    </listitem>
    <listitem>
    <para>Installer et configurer le gestionnaire de conteneurs
    <application>Incus</application> pour créer et gérer des conteneurs
    système.</para>
    </listitem>
    <listitem>
    <para>Configurer l'adressage automatique (<acronym>DHCP</acronym> et
    <acronym>SLAAC</acronym>) pour un réseau de conteneurs à l'aide de
    <application>dnsmasq</application>.</para>
    </listitem>
    <listitem>
    <para>Automatiser des tâches de gestion de conteneurs à l'aide de scripts
    <application>Bash</application>, comme l'exécution de commandes dans
    plusieurs conteneurs ou la modification de leur configuration
    réseau.</para>
    </listitem>
    </orderedlist>
</sect1>

<sect1 xml:id='inter-vlan-iaas.topology'>
    <title>Topologies logiques et virtuelles</title>

    <para>Les définitions importantes sur les réseaux locaux virtuels et le
    routage associé sont présentées dans l'article
    &url.inter-vlan-routing;</para>

    <para>Il convient de rappeler que la notion de réseau local virtuel ou
    <acronym>VLAN</acronym> permet de constituer des groupes logiques dans les
    réseaux Ethernet au niveau liaison de la modélisation. Lors du raccordement
    entre les équipements (commutateurs, routeurs, serveurs), certaines
    liaisons doivent véhiculer le trafic de plusieurs réseaux locaux virtuels
    (<acronym>VLANs</acronym>). Ces liaisons sont baptisées
    <wordasword>trunks</wordasword> dans le jargon. Pour distinguer le trafic
    appartenant à chaque réseau local, on ajoute à la trame une balise définie
    par le standard <acronym>IEEE 802.1Q</acronym>. C'est cette étiquetage de
    trame qui permet la distribution des domaines de diffusion entre plusieurs
    équipements physiques distincts.</para>

    <para>Un objectif très important est ainsi atteint. Il est désormais
    possible de concevoir une topologie logique de réseau totalement
    indépendante de la topologie physique.</para>

    <para>Réseau virtuel ou pas, il ne faut pas oublier les éléments suivants
    sur la segmentation des réseaux locaux.</para>

    <itemizedlist>
    <listitem>
        <para>Une interface de <emphasis>commutateur</emphasis> délimite un
        domaine de <emphasis>collision</emphasis>.</para>
    </listitem>
    <listitem>
        <para>Une interface de <emphasis>routeur</emphasis> délimite à la fois
        un domaine de <emphasis>collision</emphasis> et un domaine de
        <emphasis>diffusion</emphasis>.</para>
    </listitem>
    </itemizedlist>

    <para>La représentation de la topologie logique ci-dessous montre que le
    routeur de couleur verte assure l'interconnexion entre un réseau
    d'infrastructure appelé <wordasword>Hosting VLAN</wordasword> et un réseau
    de conteneurs appelé <wordasword>Container VLAN</wordasword>. Les deux
    rectangles en gris “matérialisent“ les machines virtuelles qui sont
    utilisées pour les manipulations.</para>

    <mediaobject>
    <imageobject role='html'>
    <imagedata fileref='images/inter-VLAN-logical-topology.png' format='PNG' width='700px' scalefit='1'/>
    </imageobject>
    <imageobject role='fo'>
    <imagedata fileref='images/inter-VLAN-logical-topology.png' format='PNG' width='16cm' scalefit='1'/>
    </imageobject>
    <textobject>
    <phrase>Topologie type</phrase>
    </textobject>
    <caption>
    <para><link xlink:href='images/inter-VLAN-logical-topology.png'>Topologie logique</link></para>
    </caption>
    </mediaobject>

    <para>La représentation de la topologie vue sous l'angle de l'hébergement
    sur un système hôte hyperviseur montre que les deux
    <acronym>VLANs</acronym> sont présents sur le commutateur virtuel de couche
    distribution appelé <citetitle>dsw-host</citetitle>. Ce commutateur
    appartient au système hôte. Il assure le raccordement entre les réseaux
    physiques et virtualisés. On retrouve le routeur de couleur verte raccordé
    avec un lien unique sur lequel le trafic des deux <acronym>VLANs</acronym>
    doit transiter.</para>

    <para>Côté conteneurs, seule l'interface <systemitem>enp0s1</systemitem>
    est raccordé via un lien en mode accès. La technologie
    <acronym>macVLAN</acronym> permet d'utiliser plusieurs adresses
    <acronym>MAC</acronym> sur une même interface réseau.</para>

    <mediaobject>
    <imageobject role='html'>
    <imagedata fileref='images/inter-VLAN-hosting-topology.png' format='PNG' width='700px' scalefit='1'/>
    </imageobject>
    <imageobject role='fo'>
    <imagedata fileref='images/inter-VLAN-hosting-topology.png' format='PNG' width='16cm' scalefit='1'/>
    </imageobject>
    <textobject>
    <phrase>Topologie type</phrase>
    </textobject>
    <caption>
    <para><link xlink:href='images/inter-VLAN-hosting-topology.png'>Topologie hébergée</link></para>
    </caption>
    </mediaobject>

    <table xml:id='inter-vlan-iaas.addressing' frame='all' pgwide='1'>
        <title>Plan d'adressage de la maquette « Routage inter-VLAN
        dans un contexte IaaS »</title>
    <tgroup cols='3'>
    <colspec colnum='1' colwidth='1*'/>
    <colspec colnum='2' colwidth='1*'/>
    <colspec colnum='3' colwidth='3*'/>
    <thead>
    <row>
        <?dbfo bgcolor="#333" ?>
        <?dbfo color="#fff" ?>
        <entry>Réseau</entry>
        <entry>Numéro VLAN</entry>
        <entry>Adresses de passerelles</entry>
    </row>
    </thead>
    <tbody>
    <row>
        <entry>
        <citetitle>Hébergement</citetitle><?custom-linebreak?>
        VLAN rouge
        </entry>
        <entry>360</entry>
        <entry>
        <systemitem class='ipaddress'>192.168.104.129/29</systemitem><?custom-linebreak?>
        <systemitem class='ipaddress'>2001:678:3fc:168::1/64</systemitem>
        </entry>
    </row>
    <row>
        <entry>
        <citetitle>Services</citetitle><?custom-linebreak?>
        VLAN vert
        </entry>
        <entry>440</entry>
        <entry>
        <systemitem class='ipaddress'>192.0.2.1/24</systemitem><?custom-linebreak?>
        <systemitem class='ipaddress'>fda0:7a62:1b8::1/64</systemitem>
        </entry>
    </row>
    </tbody>
    </tgroup>
    </table>
</sect1>

<sect1 xml:id='inter-vlan-iaas.vm'>
    <title>Raccordement au commutateur de distribution</title>

    <para>Dans cette section, on étudie le raccordement des deux machines
    virtuelles au commutateur de distribution sur le système hôte.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Comment contrôler la configuration des ports du commutateur
    de distribution sur le système hôte&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>Le commutateur virtuel implanté sur le système hôte est géré par
    <citetitle>Open vSwitch</citetitle>. On fait donc appel à la commande
    <command>ovs-vsctl</command> pour accéder aux paramètres de la
    configuration des ports.</para>

    <itemizedlist>
    <listitem>
    <para>Pour le port nommé <systemitem>tap200</systemitem>, on obtient le
    paramètre <systemitem>vlan_mode</systemitem> avec
    l'instruction&nbsp;:</para>
<screen>sudo ovs-vsctl get port tap200 vlan_mode
<emphasis>trunk</emphasis></screen>
    <para>Le mode <systemitem>trunk</systemitem> correspond à un canal de
    transmission unique dans lequel circule le trafic de plusieurs domaines de
    diffusion ou <acronym>VLANs</acronym>.</para>
    </listitem>
    <listitem>
    <para>Pour le port nommé <systemitem>tap2</systemitem>, on obtient la
    valeur <systemitem>access</systemitem> pour le même paramètre&nbsp;:</para>
<screen>sudo ovs-vsctl get port tap2 vlan_mode
<emphasis>access</emphasis></screen>
    <para>Ici, le mode <systemitem>access</systemitem> correspond à un canal de
    transmission dans lequel circule le trafic d'un seul et unique domaine de
    diffusion ou <acronym>VLAN</acronym>.</para>
    </listitem>
    </itemizedlist>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment afficher le numéro de <acronym>VLAN</acronym>
    attribué au port en mode accès du commutateur de distribution sur le
    système hôte&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>Reprenez la même commande que dans la question précédente avec le mot
    clé <option>tag</option>.</para>

<screen>sudo ovs-vsctl get port tap2 tag</screen>
<screen><emphasis>20</emphasis></screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment affecter le numéro de <acronym>VLAN</acronym>
    attribué au port en mode accès du commutateur de distribution sur le
    système hôte&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>On reprend à nouveau la même commande avec l'option <option>set</option>.</para>
<screen>sudo ovs-vsctl set port <emphasis>tap2 tag=440</emphasis></screen>

    <para>Les valeurs données dans l'exemple ci-dessus sont à changer suivant
    les attributions du plan d'adressage des réseaux d'hébergement et de
    conteneurs.</para>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment configurer les ports du commutateur avant le
    lancement des machines virtuelles&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>On utilise le script de procédure <filename>switch-conf.py</filename>
    qui applique les déclarations contenues dans un fichier
    <acronym>YAML</acronym>. Le code du script est accessible à partir du dépôt
    Git &url.startup-scripts;.</para>

    <para>Exemple de fichier de configuration des deux ports de
    commutateur.</para>
<screen>ovs:
  switches:
    - name: dsw-host
      ports:
        - name: tap5 # Router port
          type: OVSPort
          vlan_mode: trunk
          trunks: [360, 440]
        - name: tap6 # Container hosting VM
          type: OVSPort
          vlan_mode: access
          tag: 440</screen>

    <para>On applique les paramètres définis ci-dessus.</para>

<screen>$HOME/masters/scripts/switch-conf.py switch.yaml</screen>

    <para>On obtient les résultats suivants.</para>
<screen>----------------------------------------
Configuring switch dsw-host
>> Port tap5 vlan_mode set to trunk
>> Port tap5 trunks set to [360, 440]
>> Port tap6 vlan_mode is already set to access
>> Port tap6 tag set to 440
----------------------------------------</screen>

    <para>Les numéros de port de commutateur et de <acronym>VLAN</acronym>
    donnés dans les exemples ci-dessus sont à changer suivant le
    contexte.</para>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment lancer les machines virtuelles associées aux rôles
    routeur et hébergement de conteneurs&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>On utilise le script de procédure <filename>lab-startup.py</filename>
    qui applique les déclarations contenues dans un fichier
    <acronym>YAML</acronym>. Le code du script est accessible à partir du dépôt
    Git &url.startup-scripts;.</para>

    <para>Exemple de fichier de déclaration des deux machines
    virtuelles.</para>

<screen>kvm:
  vms:
    - vm_name: router
      master_image: debian-testing-amd64.qcow2 # master image to be used
      force_copy: false # do not force copy the master image to the VM image
      memory: 1024
      tapnum: 5
    - vm_name: hosting
      master_image: debian-testing-amd64.qcow2 # master image to be used
      force_copy: false # do not force copy the master image to the VM image
      memory: 1024
      tapnum: 6</screen>

    <para>On lance les deux machines virtuelles avec le script
    <command>lab-startup.py</command>.</para>

<screen>$HOME/masters/scripts/lab-startup.py lab1.yaml</screen>

<screen>Copying /home/etudianttest/masters/debian-testing-amd64.qcow2 to router.qcow2...done
Creating OVMF_CODE.fd symlink...
Creating router_OVMF_VARS.fd file...
Starting router...
~> Virtual machine filename   : router.qcow2
~> RAM size                   : 1024MB
~> SPICE VDI port number      : 5905
~> telnet console port number : 2305
~> MAC address                : b8:ad:ca:fe:00:05
~> Switch port interface      : tap5, trunk mode
~> IPv6 LL address            : fe80::baad:caff:fefe:5%dsw-host
router started!
Copying /home/etudianttest/masters/debian-testing-amd64.qcow2 to hosting.qcow2...done
Creating hosting_OVMF_VARS.fd file...
Starting hosting...
~> Virtual machine filename   : hosting.qcow2
~> RAM size                   : 1024MB
~> SPICE VDI port number      : 5906
~> telnet console port number : 2306
~> MAC address                : b8:ad:ca:fe:00:06
~> Switch port interface      : tap6, access mode
~> IPv6 LL address            : fe80::baad:caff:fefe:6%vlan440
hosting started!</screen>

    <para>Les deux machines virtuelles sont maintenant disponibles pour la
    suite des manipulations.</para>
    </answer>
    </qandaentry>
    </qandaset>
</sect1>

<sect1 xml:id='inter-vlan-iaas.router'>
    <title>Rôle routeur</title>

    <para>Dans cette section, on étudie la machine virtuelle qui joue le rôle
    de routeur entre le réseau d'hébergement et un réseau de conteneurs. Pour
    traiter les questions, il est nécessaire de mettre en œuvre une maquette
    avec un adressage indépendant. Voici les choix effectués pour la
    maquette.</para>

    <sect2 xml:id='inter-vlan-iaas.router.interfaces'>
        <title>Configuration des interfaces du routeur</title>

    <para>Une fois la machine virtuelle routeur lancée, les premières étapes
    consistent à lui attribuer un nouveau nom et à configurer les interfaces
    réseau pour joindre les hôtes voisins.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Comment changer le nom de la machine
    virtuelle&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>Éditer le fichier <filename>/etc/hostname</filename> en
    remplaçant le nom local par le nom voulu. Il est ensuite nécessaire de
    redémarrer pour que le nouveau nom soit pris en compte par tous les outils
    du système.</para>

<screen><prompt>etu@localhost:~$</prompt> sudo hostnamectl hostname router
<prompt>etu@vm0:~$</prompt> sudo reboot</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment appliquer les configurations réseau
    <acronym>IPv4</acronym> et <acronym>IPv6</acronym> à partir de l'unique
    interface du routeur&nbsp;?</phrase></para>

    <para>Consulter la documentation de <citetitle>Netplan</citetitle> pour
    obtenir les informations sur la configuration des interfaces réseau à
    l'adresse &url.netplan-doc;.</para>
    </question>
    <answer>
    <para>Il existe plusieurs possibilités pour configurer une interface
    réseau. Dans le contexte de ces manipulations, on utilise
    <citetitle>Netplan</citetitle> dans le but de séparer la partie déclarative
    du moteur de configuration.</para>

    <para>C'est <systemitem>systemd-networkd</systemitem> qui joue le rôle de
    moteur de configuration sur les machines virtuelles utilisées avec ces
    manipulations.</para>

    <para>La configuration de base fournie avec l'image maître suppose que
    l'interface obtienne un bail <acronym>DHCP</acronym> pour la partie
    <acronym>IPv4</acronym> et une configuration automatique via
    <acronym>SLAAC</acronym> pour la partie <acronym>IPv6</acronym>. Cette
    configuration par défaut doit être éditée et remplacée. Il faut configurer
    trois interfaces.</para>

    <itemizedlist>
    <listitem>
    <para>L'interface principale correspond à l'interface
    &laquo;&nbsp;physique&nbsp;&raquo; de la machine. Elle est nommée
    <systemitem>enp0s1</systemitem> en fonction de l'ordre des adresses des
    composants raccordés au bus <acronym>PCI</acronym>.</para>
    </listitem>
    <listitem>
    <para>Une sous-interface doit être créée pour le réseau d'hébergement avec
    le numéro de <acronym>VLAN</acronym> désigné dans le plan d'adressage des
    réseaux d'hébergement et de conteneurs. Cette interface doit désigner les
    passerelles <acronym>IPv4</acronym> et <acronym>IPv6</acronym> de façon à
    joindre l'Internet.</para>
    </listitem>
    <listitem>
    <para>Une sous-interface doit être créée pour le réseau des conteneurs avec,
    là encore, le bon numéro de <acronym>VLAN</acronym>. Les adresses
    <acronym>IPv4</acronym> et <acronym>IPv6</acronym> de cette interface
    deviendront les passerelles du serveur et des conteneurs.</para>
    </listitem>
    </itemizedlist>

    <para>Exemple de fichier
    <filename>/etc/netplan/enp0s1.yaml</filename> de la maquette.</para>

<screen>network:
    version: 2
    ethernets:
      enp0s1:
        dhcp4: false
        dhcp6: false
        accept-ra: false
        nameservers:
          addresses:
            - 172.16.0.2
            - 2001:678:3fc:3::2

    vlans:
      enp0s1.360:
        id: 360
        link: enp0s1
        addresses:
          - 192.168.104.130/29
          - 2001:678:3fc:168::82/64
        routes:
          - to: default
            via: 192.168.104.129
          - to: "::/0"
            via: "fe80::168:1"
            on-link: true
      enp0s1.440:
        id: 440
        link: enp0s1
        addresses:
          - 192.0.2.1/24
          - fda0:7a62:1b8::1/64</screen>

    <para>Une fois le fichier de configuration en place, il suffit de faire
    appel à la commande <command>netplan</command> pour appliquer les
    changements.</para>

<screen>sudo netplan apply</screen>

    <para>Pour vérifier que l'adressage réseau est correct, on dispose de
    plusieurs solutions. Exemple avec la commande <command>networkctl</command>
    qui synthétise l'ensemble de la configuration réseau.</para>

<screen>networkctl status</screen>

<screen>● Interfaces: 1, 2, 3, 4
    State: routable
Online state: online
  Address: 192.168.104.130 on enp0s1.360
           192.0.2.1 on enp0s1.440
           2001:678:3fc:168::82 on enp0s1.360
           2001:678:3fc:168:baad:caff:fefe:5 on enp0s1.360
           fda0:7a62:1b8::1 on enp0s1.440
           fe80::baad:caff:fefe:5 on enp0s1
           fe80::baad:caff:fefe:5 on enp0s1.360
           fe80::baad:caff:fefe:5 on enp0s1.440
  Gateway: 192.168.104.129 on enp0s1.360
           fe80:168::1 on enp0s1.360
      DNS: 172.16.0.2
           2001:678:3fc:3::2</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Quels sont les tests de connectivité réalisables après
    application de la nouvelle configuration des interfaces
    réseau&nbsp;?</phrase></para>

    <para>Relever l'état des trois interfaces et procédez aux tests
    <acronym>ICMP</acronym> et <acronym>DNS</acronym> en respectant l'ordre des
    couches de la modélisation.</para>
    </question>
    <answer>
    <para>Sans la confirmation que la configuration du serveur de conteneurs
    est prête, c'est du côté hébergement et accès Internet qu'il faut orienter
    les tests. Classiquement, on cherche à joindre la passerelle en premier
    puis l'Internet ensuite via des requêtes <acronym>ICMP</acronym>. Enfin, on
    effectue un test de couche application avec une requête
    <acronym>DNS</acronym>.</para>

<screen>ping -q -c2 192.168.104.129
PING 192.168.104.129 (192.168.104.129) 56(84) bytes of data.

--- 192.168.104.129 ping statistics ---
<emphasis>2 packets transmitted, 2 received, 0% packet loss</emphasis>, time 1002ms
rtt min/avg/max/mdev = 1.501/1.516/1.531/0.015 ms</screen>

<screen>PING 9.9.9.9 (9.9.9.9) 56(84) bytes of data.

--- 9.9.9.9 ping statistics ---
<emphasis>2 packets transmitted, 2 received, 0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 49.304/52.098/54.892/2.794 ms</screen>

<screen>ping -q -c2 fe80:168::1%enp0s1.360
PING fe80:168::1%enp0s1.360(fe80:168::1%enp0s1.360) 56 data bytes

--- fe80:168::1%enp0s1.360 ping statistics ---
<emphasis>2 packets transmitted, 2 received, 0% packet loss</emphasis>, time 1000ms
rtt min/avg/max/mdev = 1.459/13.305/25.152/11.846 ms</screen>

<screen>ping -q -c2 2620:fe::fe
PING 2620:fe::fe(2620:fe::fe) 56 data bytes

--- 2620:fe::fe ping statistics ---
<emphasis>2 packets transmitted, 2 received, 0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 41.812/42.437/43.063/0.625 ms</screen>

<screen>host quad9.net
quad9.net has address 216.21.3.77
quad9.net has IPv6 address 2620:0:871:9000::77
quad9.net mail is handled by 5 mx1.quad9.net.
quad9.net mail is handled by 20 mx2.quad9.net.
quad9.net mail is handled by 100 keriomail.pch.net.</screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>

    <sect2 xml:id='inter-vlan-iaas.router.routing'>
        <title>Activation de la fonction routage</title>

    <para>Sans modification de la configuration par défaut, un système
    GNU/Linux n'assure pas la fonction de routage du trafic d'une interface
    réseau à une autre.</para>

    <para>L'activation du routage correspond à un réglage de certains
    paramètres du sous-système réseau du noyau Linux. L'outil qui permet de
    consulter et modifier les réglages de paramètre sur le noyau est appelé
    <application>sysctl</application>.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Comment activer le routage dans le sous-système réseau du
    noyau Linux&nbsp;?</phrase></para>

    <para>Utiliser la commande <command>sysctl</command> pour effectuer des
    recherches et identifier les paramètres utiles. Par exemple&nbsp;:</para>

<screen>sudo sysctl -a -r ".*forward.*"</screen>

    <para>Il est dorénavant recommandé de créer un fichier de configuration
    spécifique par fonction.  C'est la raison pour laquelle on crée un nouveau
    fichier <filename>/etc/sysctl.d/10-routing.conf</filename>.</para>

    <para>Attention ! Il ne faut pas oublier d'appliquer les nouvelles valeurs
    des paramètres de configuration.</para>
    </question>
    <answer>

<screen>cat &lt;&lt; EOF | sudo tee /etc/sysctl.d/10-routing.conf
net.ipv4.ip_forward=1
net.ipv6.conf.all.forwarding=1
net.ipv4.conf.all.log_martians=1
EOF</screen>

    <para>Exemple des résultats obtenus après application des nouveaux
    paramètres.</para>

<screen>sudo sysctl --system</screen>

<screen>* Applique /usr/lib/sysctl.d/10-coredump-debian.conf …
<emphasis>* Applique /etc/sysctl.d/10-routing.conf …</emphasis>
* Applique /usr/lib/sysctl.d/50-default.conf …
* Applique /usr/lib/sysctl.d/50-pid-max.conf …
* Applique /etc/sysctl.conf …
kernel.core_pattern = core
<emphasis>net.ipv4.ip_forward = 1</emphasis>
<emphasis>net.ipv6.conf.all.forwarding = 1</emphasis>
<emphasis>net.ipv4.conf.all.log_martians = 1</emphasis>
kernel.sysrq = 0x01b6
kernel.core_uses_pid = 1
net.ipv4.conf.default.rp_filter = 2
net.ipv4.conf.enp0s1/360.rp_filter = 2
net.ipv4.conf.enp0s1/440.rp_filter = 2
net.ipv4.conf.enp0s1.rp_filter = 2
net.ipv4.conf.lo.rp_filter = 2
net.ipv4.conf.default.accept_source_route = 0
net.ipv4.conf.enp0s1/360.accept_source_route = 0
net.ipv4.conf.enp0s1/440.accept_source_route = 0
net.ipv4.conf.enp0s1.accept_source_route = 0
net.ipv4.conf.lo.accept_source_route = 0
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.enp0s1/360.promote_secondaries = 1
net.ipv4.conf.enp0s1/440.promote_secondaries = 1
net.ipv4.conf.enp0s1.promote_secondaries = 1
net.ipv4.conf.lo.promote_secondaries = 1
net.ipv4.ping_group_range = 0 2147483647
net.core.default_qdisc = fq_codel
fs.protected_hardlinks = 1
fs.protected_symlinks = 1
fs.protected_regular = 2
fs.protected_fifos = 1
kernel.pid_max = 4194304</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Quelles sont les conditions à réunir pour tester le
    fonctionnement du routage&nbsp;?</phrase></para>

    <para>Rechercher comment utiliser l'analyseur réseau
    <application>tshark</application> pour caractériser l'acheminement du
    trafic d'un réseau à l'autre.</para>
    </question>
    <answer>
    <para>Le plan d'adressage prévoit d'utiliser des préfixes ayant une portée
    locale pour les réseaux de conteneurs. Il n'est donc pas possible de
    passer par une requête <acronym>ICMP</acronym> pour caractériser l'accès
    aux réseaux distants. En effet, l'adresse source n'est pas reconnue par
    l'hôte distant et les routeurs de l'Internet ne disposent d'aucune solution
    pour joindre le réseau des conteneurs.</para>

    <para>Voici un extrait de capture qui montre que le serveur de conteneur
    cherche à joindre un hôte sur l'Internet sans succès. Cette capture étant
    réalisée sur l'interface réseau côté hébergement, elle montre que le trafic
    est bien acheminé d'un réseau à l'autre.</para>

<screen>tshark -i enp0s1.360</screen>
<screen>Capturing on 'enp0s1.360'
    1 0.000000000    192.0.2.2 → 9.9.9.9      DNS 81 Standard query 0xbdab A 1.debian.pool.ntp.org
    2 0.000056361    192.0.2.2 → 9.9.9.9      DNS 81 Standard query 0xab92 AAAA 1.debian.pool.ntp.org</screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>

    <sect2 xml:id='inter-vlan-iaas.router.nat'>
        <title>Activation de la traduction d'adresses</title>

    <para>Le résultat de la question ci-dessus montre que les hôtes situés dans
    le réseau des conteneurs ne peuvent pas joindre l'Internet puisque les
    préfixes réseau utilisés ont une portée limitée.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Quels sont les paquets qui fournissent les outils de gestion
    de la traduction d'adresses&nbsp;?</phrase></para>

    <para>Rechercher les paquets relatifs au filtrage et à la gestion des
    règles de pare-feux.</para>

    <para>Dans le contexte des ces manipulations, nous utilisons
    <systemitem>nftables</systemitem> comme outil de gestion du
    filtrage.</para>
    </question>
    <answer>
    <para>C'est la partie outils de l'espace utilisateur qui nous intéresse
    ici.</para>

<screen>apt search ^nftables$
nftables/testing,now 1.1.0-2 amd64  [installé]
  programme de contrôle des règles de filtrage de paquets du projet Netfilter</screen>

<screen>sudo apt -y install nftables</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Quelles sont les règles à appliquer pour assurer une
    traduction des adresses sources en sortie sur le réseau d'infrastructure
    (VLAN rouge)&nbsp;?</phrase></para>

    <para>Rechercher dans des exemples de configuration
    <systemitem>nftables</systemitem> avec la fonction
    <literal>MASQUERADE</literal>.</para>
    </question>
    <answer>
    <para>Exemple de création du fichier
    <filename>/etc/nftables.conf</filename> avec le jeu d'instructions qui
    assure la traduction d'adresses sources pour <acronym>IPv4</acronym> et
    <acronym>IPv6</acronym>.</para>

<screen>cat &lt;&lt; EOF | sudo tee /etc/nftables.conf
#!/usr/sbin/nft -f

flush ruleset

table inet nat {
    chain postrouting {
        type nat hook postrouting priority 100;
        oifname <emphasis>"enp0s1.360"</emphasis> counter packets 0 bytes 0 masquerade
    }
}
EOF</screen>

    <warning>
    <para>Il faut impérativement changer le nom d'interface en utilisant le
    numéro de <acronym>VLAN</acronym> attribué dans le plan d'adressage des
    travaux pratiques.</para>
    </warning>

	<para>La création de ce fichier de règles n'est pas suffisante. Il faut
	appliquer les règles contenues dans le fichier.</para>

<screen>sudo nft -f /etc/nftables.conf</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment rendre le chargement des règles de filtrage
    automatique au redémarrage du système&nbsp;?</phrase></para>

    <para>Afficher l'état du service <systemitem>nftables.service</systemitem>.
    Activer ce service si celui est à l'état désactivé
    (<wordasword>disabled</wordasword>).</para>
    </question>
    <answer>
    <para>Pour afficher l'état du service, on utilise la commande suivante.</para>

<screen>systemctl status nftables.service</screen>

<screen>○ nftables.service - nftables
     Loaded: loaded (/usr/lib/systemd/system/nftables.service; <emphasis>disabled</emphasis>; preset: enabled)
     Active: inactive (dead)
       Docs: man:nft(8)
             http://wiki.nftables.org</screen>

	<para>On constate qu'il faut activer ce service pour assurer le chargement
automatique des règles de filtrage au démarrage.</para>

<screen>sudo systemctl enable nftables.service
sudo systemctl start nftables.service
sudo systemctl status nftables.service</screen>

<screen>● nftables.service - nftables
     Loaded: loaded (/usr/lib/systemd/system/nftables.service; <emphasis>enabled</emphasis>; preset: enabled)
     Active: active (exited) since Sat 2024-09-14 18:35:00 CEST; 7s ago
 Invocation: 1dcc395a33c74606bd7dab7f33b90787
       Docs: man:nft(8)
             http://wiki.nftables.org
    Process: 729 ExecStart=<emphasis>/usr/sbin/nft -f /etc/nftables.conf (code=exited, status=0/SUCCESS)</emphasis>
   Main PID: 729 (code=exited, status=0/SUCCESS)
   Mem peak: 5.9M
        CPU: 44ms

sept. 14 18:34:59 router systemd[1]: Starting nftables.service - nftables...
sept. 14 18:35:00 router systemd[1]: Finished nftables.service - nftables.</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment caractériser le fonctionnement de la traduction
    d'adresses sources&nbsp;?</phrase></para>

    <para>Rechercher dans les pages de manuel de la commande
    <command>nftables</command> les options d'affichage du décompte du trafic
    traité.</para>
    </question>
    <answer>
    <para>Exemple d'affichage des règles actives avec visualisation
    des compteurs d'utilisation.</para>

<screen>sudo nft list ruleset</screen>

<screen>table inet nat {
        chain postrouting {
                type nat hook postrouting priority srcnat; policy accept;
                oifname <emphasis>"enp0s1.360"</emphasis> counter <emphasis>packets 45 bytes 3424</emphasis> masquerade
        }
}</screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>

    <sect2 xml:id='inter-vlan-iaas.router.radvd'>
        <title>Activation de l'adressage  automatique pour le réseau de
        conteneurs</title>

	<para>Dans le but mettre en place un adressage automatique des conteneurs
	hébergés sur l'autre machine virtuelle, on utilise l'outil
	<systemitem>dnsmasq</systemitem>. L'idée est de fournir un service
	<acronym>DHCPv4</acronym> et <acronym>SLAAC</acronym> en un seul et unique
	fichier de configuration.</para>

    <para>On débute par l'installation du paquet.</para>

<screen>sudo apt -y install dnsmasq</screen>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
	<para><phrase>Comment remplacer le fichier de configuration fourni lors de
	l'installation du paquet par notre propre fichier de
	configuration&nbsp;?</phrase></para>

	<para>Consulter le contenu du fichier
	<filename>/etc/dnsmasq.conf</filename> et extraire les options de configuration
	utiles au contexte de ces manipulations.</para>
    </question>
    <answer>
	<para>Exemple de commande de copie du fichier issu de l'installation.</para>

<screen>sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.dist</screen>

    <para>Exemple de configuration adaptée à la maquette.</para>

<screen>cat &lt;&lt; EOF | sudo tee /etc/dnsmasq.conf
# Specify Container VLAN interface
interface=<emphasis>enp0s1.440</emphasis>

# Enable DHCPv4 on Container VLAN
dhcp-range=<emphasis>192.0.2.20,192.0.2.200</emphasis>,3h

# Enable IPv6 router advertisements
enable-ra

# Enable SLAAC
dhcp-range=::,constructor:<emphasis>enp0s1.440</emphasis>,ra-names,slaac

# Optional: Specify DNS servers
dhcp-option=option:dns-server,172.16.0.2,9.9.9.9
dhcp-option=option6:dns-server,[2001:678:3fc:3::2],[260:fe::fe]

# Avoid DNS listen port conflict between dnsmasq and systemd-resolved
port=0
EOF</screen>

    <warning>
    <para>Il faut impérativement changer le numéro de VLAN ainsi que les
    adresses <acronym>IPv4</acronym> de l'exemple ci-dessus par les
    informations données dans le plan d'adressage des travaux pratiques.</para>

    <para>De plus, une fois le fichier créé, il ne faut pas oublier de
    redémarrer le service et de contrôler l'état de son fonctionnement.</para>
    </warning>

<screen>sudo systemctl restart dnsmasq
systemctl status dnsmasq</screen>

<screen>● dnsmasq.service - dnsmasq - A lightweight DHCP and caching DNS server
     Loaded: loaded (/usr/lib/systemd/system/dnsmasq.service; enabled; preset: enabled)
     Active: <emphasis>active (running)</emphasis> since Sat 2024-09-14 18:49:02 CEST; 10min ago
 Invocation: 8887da64fc36432db7be668ec71cbfb7
    Process: 1072 ExecStartPre=/usr/share/dnsmasq/systemd-helper checkconfig (code=exited, status=0/SUCCESS)
    Process: 1077 ExecStart=/usr/share/dnsmasq/systemd-helper exec (code=exited, status=0/SUCCESS)
    Process: 1084 ExecStartPost=/usr/share/dnsmasq/systemd-helper start-resolvconf (code=exited, status=0/SUCCESS)
   Main PID: 1083 (dnsmasq)
      Tasks: 1 (limit: 1087)
     Memory: 720K (peak: 2.8M)
        CPU: 94ms
     CGroup: /system.slice/dnsmasq.service
			 └─1083 /usr/sbin/dnsmasq -x /run/dnsmasq/dnsmasq.pid -u dnsmasq -r /run/dnsmasq/resolv.conf \
						-7 /etc/dnsmasq.d,.dpkg-dist,.dpkg-old,.dpkg-new --local-service
						--trust-anchor=.,20326,8,2,e06d44b80b8f1d39a95c0b0d7c65d08458e880409bbc683457104237c7f8ec8d

sept. 14 18:49:02 router systemd[1]: <emphasis>Started dnsmasq.service - dnsmasq - A lightweight DHCP and caching DNS server.</emphasis></screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>
</sect1>

<sect1 xml:id='inter-vlan-iaas.server'>
    <title>Rôle serveur de conteneurs</title>

    <sect2 xml:id='inter-vlan-iaas.server.interfaces'>
        <title>Configuration de l'interface du serveur</title>

    <para>Une fois la machine virtuelle serveur de conteneurs lancée, les
    premières étapes consistent à lui attribuer un nouveau nom et à configurer
    les interfaces réseau pour joindre le routeur voisin et l'Internet.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Comment changer le nom de la machine
    virtuelle&nbsp;?</phrase></para>
    </question>
    <answer>
    <para>Attribuez le nom d'hôte à l'aide de la commande
    <command>hostnamectl</command> et redémarrer le système.</para>

<screen>sudo hostnamectl hostname hosting
sudo reboot</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment appliquer les configurations réseau
    <acronym>IPv4</acronym> et <acronym>IPv6</acronym> à partir de l'unique
    interface de la machine d'hébergement&nbsp;?</phrase></para>

    <para>Consulter la documentation de <citetitle>Netplan</citetitle> pour
    obtenir les informations sur la configuration des interfaces réseau à
    l'adresse &url.netplan-doc;.</para>
    </question>
    <answer>
    <para>Il existe plusieurs possibilités pour configurer une interface
    réseau. Dans le contexte de ces manipulations, on utilise
    <citetitle>Netplan</citetitle> dans le but de séparer la partie déclarative
    du moteur de configuration.</para>

    <para>C'est <systemitem>systemd-networkd</systemitem> qui joue le rôle de
    moteur de configuration sur les machines virtuelles utilisées avec ces
    manipulations.</para>

    <para>La configuration de base fournie avec l'image maître suppose que
    l'interface obtienne un bail <acronym>DHCP</acronym> pour la partie
    <acronym>IPv4</acronym> et une configuration automatique via
    <acronym>SLAAC</acronym> pour la partie <acronym>IPv6</acronym>. Cette
    configuration par défaut doit être éditée et remplacée.</para>

	<itemizedlist>
	<listitem>
	<para>L'interface réseau appartient un seul et unique domaine de
	diffusion&nbsp;: le <acronym>VLAN</acronym> 440 dans le contexte de cette
	maquette.</para>
    </listitem>
	<listitem>
	<para>On fait le choix d'attribuer des adresses statiques à l'interface
	<systemitem>enp0s1</systemitem> pour être en mesure de tester le routage et
	la traduction d'adresses sources au niveau du routeur. Ainsi, on ne dépend
	pas du service <systemitem>dnsmasq</systemitem> pour les tests de
	communication.</para>
	</listitem>
	</itemizedlist>

	<para>Exemple de fichier
	<filename>/etc/netplan/enp0s1.yaml</filename> de la maquette.</para>

<screen>cat &lt;&lt; EOF | sudo tee /etc/netplan/enp0s1.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    enp0s1:
      dhcp4: false
      dhcp6: false
      accept-ra: true
      addresses:
        - 192.0.2.2/24
        - fda0:7a62:1b8::2/64
      routes:
        - to: default
          via: 192.0.2.1
        - to: "::/0"
          via: fe80::baad:caff:fefe:5
          on-link: true
      nameservers:
        addresses:
          - 172.16.0.2
          - 2001:678:3fc:3::2
EOF</screen>

	<para>Bien sûr, il ne faut pas oublier d'appliquer les paramètre de
	configuration de l'interface.</para>

<screen>sudo netplan apply</screen>
    </answer>
    </qandaentry>
    <qandaentry>
    <question>
    <para><phrase>Comment valider la configuration réseau du serveur de
    conteneurs&nbsp;?</phrase></para>

    <para>Lancer une série de tests <acronym>ICMP</acronym>
    <acronym>IPv4</acronym> et <acronym>IPv6</acronym>.</para>
    </question>
    <answer>
    <para>On reprend les tests usuels avec les commandes
    <command>ping</command> et <command>host</command>.</para>

<screen><prompt>etu@server:~$</prompt> ping -qc2 9.9.9.9
PING 9.9.9.9 (9.9.9.9) 56(84) bytes of data.

--- 9.9.9.9 ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1002ms
rtt min/avg/max/mdev = 19.433/19.586/19.740/0.153 ms</screen>

<screen><prompt>etu@server:~$</prompt> ping -qc2 2620:fe::fe
PING 2620:fe::fe(2620:fe::fe) 56 data bytes

--- 2620:fe::fe ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 42.983/43.114/43.246/0.131 ms</screen>

<screen><prompt>etu@server:~$</prompt> host kernel.org
kernel.org has address 139.178.84.217
kernel.org has IPv6 address 2604:1380:4641:c500::1
kernel.org mail is handled by 10 smtp1.kernel.org.
kernel.org mail is handled by 10 smtp3.kernel.org.
kernel.org mail is handled by 10 smtp2.kernel.org.</screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>

    <sect2 xml:id='inter-vlan-iaas.incus.install'>
        <title>Installation du gestionnaire de conteneurs Incus</title>

    <para>Sur l'hôte qui tient le rôle de serveur d'hébergement, la gestion des
    conteneurs est confiée à &url.incus;.</para>

    <para>Selon l'exergue du site, <citetitle>Incus</citetitle> est un
    gestionnaire de conteneurs et de machines virtuelles puissant, sûr et
    moderne.</para>

    <para>Dans le contexte de ces manipulations, c'est la variété des modes
    d'interconnexion réseau offerte par <citetitle>Incus</citetitle> qui est le
    point le plus déterminant. Ici on utilise le mode &url.macvlan; qui
    raccorde les conteneurs au même domaine de diffusion que la machine hôte.
    C'est le mode de raccordement le plus simple. Cependant, il n'autorise pas
    les communications entre les conteneurs du fait de l'isolation des espaces
    de noms.</para>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Comment installer le gestionnaire de conteneurs
    <application>Incus</application>&nbsp;?</phrase></para>

    <para>Lancer une recherche  dans la liste des paquets Debian.</para>
    </question>
    <answer>
    <para>Le paquet s'appelle tout simplement
    <application>incus</application>.</para>

<screen>apt search ^incus</screen>

<screen>sudo apt -y install incus</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment faire pour que l'utilisateur normal
    <literal>etu</literal> devienne administrateur et gestionnaire des
    conteneurs&nbsp;?</phrase></para>

    <para>Rechercher le nom du groupe système correspondant à l'utilisation des
    outils <application>Incus</application>.</para>
    </question>
    <answer>
    <para>Il faut que l'utilisateur normal appartienne au groupes systèmes
    <systemitem>incus</systemitem> et <systemitem>incus-admin</systemitem> pour
    qu'il ait tous les droits sur la gestion des conteneurs.</para>

<screen>grep incus /etc/group
incus:x:990:
incus-admin:x:989:</screen>

<screen>sudo adduser etu incus
sudo adduser etu incus-admin</screen>

    <warning>
    <para>Attention&nbsp;! Il faut se déconnecter/reconnecter pour bénéficier
    de la nouvelle attribution de groupe. On peut utiliser les commandes
    <command>groups</command> ou <command>id</command> pour vérifier le
    résultat.</para>
    </warning>

<screen>groups
etu adm sudo users <emphasis>incus-admin</emphasis> <emphasis>incus</emphasis></screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>

    <sect2 xml:id='inter-vlan-iaas.incus.init'>
        <title>Configuration du gestionnaire de conteneurs Incus</title>

    <qandaset defaultlabel='number'>
    <qandaentry>
    <question>
    <para><phrase>Quelle est l'instruction de configuration initiale du
    gestionnaire <application>Incus</application>&nbsp;?</phrase></para>

    <para>Utiliser l'aide de la commande <command>incus</command>.</para>
    </question>
    <answer>
    <para>C'est l'instruction <userinput>incus admin init</userinput> qui nous
    intéresse.</para>

    <para>Copie d'écran de son exécution.</para>

<screen>incus admin init</screen>

<screen>Would you like to use clustering? (yes/no) [default=no]:
Do you want to configure a new storage pool? (yes/no) [default=yes]:
Name of the new storage pool [default=default]:
Would you like to create a new local network bridge? (yes/no) [default=yes]: <emphasis>no</emphasis>
Would you like to use an existing bridge or host interface? (yes/no) [default=no]: <emphasis>yes</emphasis>
Name of the existing bridge or host interface: <emphasis>enp0s1</emphasis>
Would you like the server to be available over the network? (yes/no) [default=no]:
Would you like stale cached images to be updated automatically? (yes/no) [default=yes]:
Would you like a YAML "init" preseed to be printed? (yes/no) [default=no]:</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Quelle est l'instruction qui permet d'afficher le profil par
    défaut des conteneurs&nbsp;?</phrase></para>

    <para>Rechercher dans les options de la commande
    <command>incus profile</command>.</para>
    </question>
    <answer>
    <para>Exemple d'exécution.</para>

<screen>incus profile show default</screen>

<screen>config: {}
description: Default Incus profile
devices:
  eth0:
    name: eth0
    nictype: <emphasis>macvlan</emphasis>
    parent: <emphasis>enp0s1</emphasis>
    type: <emphasis>nic</emphasis>
  root:
    path: /
    pool: <emphasis>default</emphasis>
    type: disk
name: default
used_by: []
project: default</screen>

    <para>L'affichage de ce profil par défaut permet de vérifier que tous les
    paramètres voulus sont correctement positionnés.</para>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Quelle est l'instruction de création et de lancement de
    nouveaux conteneurs&nbsp;?</phrase></para>

    <para>Rechercher dans les options de la commande
    <command>incus</command>.</para>

    <para>Tester son exécution avec un conteneur de type
    <literal>debian/trixie</literal>.</para>
    </question>
    <answer>
    <para>Exemple d'exécution pour 3 nouveaux conteneurs.</para>

<screen>for i in {0..2}; do incus launch images:debian/trixie c$i; done</screen>

<screen>Launching c0
Launching c1
Launching c2</screen>

<screen>incus ls</screen>

<screen>+------+---------+--------------------+-------------------------------------------+-----------+-----------+
| NAME |  STATE  |        IPV4        |                   IPV6                    |   TYPE    | SNAPSHOTS |
+------+---------+--------------------+-------------------------------------------+-----------+-----------+
| c0   | RUNNING | 192.0.2.52 (eth0)  | fda0:7a62:1b8:0:216:3eff:febd:a233 (eth0) | CONTAINER | 0         |
+------+---------+--------------------+-------------------------------------------+-----------+-----------+
| c1   | RUNNING | 192.0.2.133 (eth0) | fda0:7a62:1b8:0:216:3eff:fe8e:cc62 (eth0) | CONTAINER | 0         |
+------+---------+--------------------+-------------------------------------------+-----------+-----------+
| c2   | RUNNING | 192.0.2.187 (eth0) | fda0:7a62:1b8:0:216:3eff:fe7d:6898 (eth0) | CONTAINER | 0         |
+------+---------+--------------------+-------------------------------------------+-----------+-----------+</screen>

    <para>La copie d'écran ci-dessus montre que l'adressage automatique des
    conteneurs depuis le routeur a fonctionné.</para>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment tester les communications réseau depuis chaque
    conteneur&nbsp;?</phrase></para>

    <para>Rechercher dans les options de la commande <command>incus</command>
    celle qui permet de lancer un traitement dans le conteneur.</para>
    </question>
    <answer>
    <para>C'est la commande <command>incus exec</command> qui correspond à
    notre besoin. Exemple de boucle qui permet de lancer les tests
    <acronym>ICMP</acronym> <acronym>IPv4</acronym> et <acronym>IPv6</acronym>
    dans les 3 conteneurs actifs.</para>

<screen>for i in {0..2}
do
    echo ">>>>>>>>>>>>>>>>> c$i"
    incus exec c$i -- ping -qc2 9.9.9.9
    incus exec c$i -- ping -qc2 2620:fe::fe
done</screen>

<screen>PING 9.9.9.9 (9.9.9.9) 56(84) bytes of data.

--- 9.9.9.9 ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1002ms
rtt min/avg/max/mdev = 27.887/28.676/29.465/0.789 ms
PING 2620:fe::fe (2620:fe::fe) 56 data bytes

--- 2620:fe::fe ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 41.727/48.212/54.697/6.485 ms
>>>>>>>>>>>>>>>>> c1
PING 9.9.9.9 (9.9.9.9) 56(84) bytes of data.

--- 9.9.9.9 ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 28.179/34.740/41.302/6.561 ms
PING 2620:fe::fe (2620:fe::fe) 56 data bytes

--- 2620:fe::fe ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1001ms
rtt min/avg/max/mdev = 40.002/40.529/41.057/0.527 ms
>>>>>>>>>>>>>>>>> c2
PING 9.9.9.9 (9.9.9.9) 56(84) bytes of data.

--- 9.9.9.9 ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1002ms
rtt min/avg/max/mdev = 28.539/35.408/42.278/6.869 ms
PING 2620:fe::fe (2620:fe::fe) 56 data bytes

--- 2620:fe::fe ping statistics ---
2 packets transmitted, 2 received, <emphasis>0% packet loss</emphasis>, time 1002ms
rtt min/avg/max/mdev = 40.428/47.517/54.606/7.089 ms</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment exécuter des jeux d'instructions dans les conteneurs
    depuis le serveur d'hébergement&nbsp;?</phrase></para>

    <para>On entre ici dans le domaine de l'automatisation à l'aide de scripts
    <citetitle>Bash</citetitle>. Même si l'ambition reste très modeste, on peut
    développer un script qui utilise la liste des conteneurs actifs pour lancer
    une suite de traitements dans ces mêmes conteneurs.</para>

    <para>Comme les conteneurs <citetitle>Incus</citetitle> appartiennent à la
    famille des conteneurs système, ils disposent d'une arborescence complète
    et d'une gestion de paquets. Allons y pour une mise à jour des paquets de
    chaque conteneur actif.</para>
    </question>
    <answer>
    <para>Exemple de code qui stocke les commandes à lancer dans un
    tableau et qui les exécute sur chacun des conteneurs actifs.</para>

<screen>#!/bin/bash

cmds=(
  "apt -y update"
  "apt -y full-upgrade"
  "apt -y clean"
  "apt -y autopurge"
)

clist=$(incus list status=running -c n -f compact | grep -v NAME | tr '\n' ' ' | tr -s ' ')

for c in $clist; do
  echo ">>>>>>>>>>>>>>>>> $c"
  for cmd in "${cmds[@]}"; do
    eval "incus exec $c -- $cmd"
  done
done

exit 0</screen>

    <para>Si ce script est enregistré dans le fichier
    <filename>run-commands-in-containers.sh</filename>, on peut lancer les
    traitements comme dans l'exemple ci-dessous.</para>

<screen>bash run-commands-in-containers.sh
>>>>>>>>>>>>>>>>> c0
Hit:1 http://deb.debian.org/debian trixie InRelease
Hit:2 http://deb.debian.org/debian trixie-updates InRelease
Hit:3 http://deb.debian.org/debian-security trixie-security InRelease
All packages are up to date.
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0
>>>>>>>>>>>>>>>>> c1
Hit:1 http://deb.debian.org/debian trixie InRelease
Hit:2 http://deb.debian.org/debian trixie-updates InRelease
Hit:3 http://deb.debian.org/debian-security trixie-security InRelease
All packages are up to date.
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0
>>>>>>>>>>>>>>>>> c2
Hit:1 http://deb.debian.org/debian trixie InRelease
Hit:2 http://deb.debian.org/debian trixie-updates InRelease
Hit:3 http://deb.debian.org/debian-security trixie-security InRelease
All packages are up to date.
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0
Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 0</screen>

    <para>Pour compléter, voici une seconde version du script qui utilise les
    arguments de la ligne de commande pour remplir le tableau des commandes à
    exécuter.</para>

<screen>#!/bin/bash

cmds=("$@")

clist=$(incus list status=running -c n -f compact | grep -v NAME | tr '\n' ' ' | tr -s ' ')

for c in $clist; do
  echo ">>>>>>>>>>>>>>>>> $c"
  for cmd in "${cmds[@]}"; do
    eval "incus exec $c -- $cmd"
  done
done</screen>
    </answer>
    </qandaentry>

    <qandaentry>
    <question>
    <para><phrase>Comment passer d'un adressage automatique à un adressage
    statique pour chaque conteneur&nbsp;?</phrase></para>

    <para>Comme la gestion de la configuration des interfaces est assurée par
    <systemitem>systemd-networkd</systemitem>, il faut s'intéresser à la
    syntaxe du fichier <filename>/etc/systemd/network/eth0.network</filename>
    de chaque conteneur.</para>

    <para>Cette question est un prétexte pour utiliser le transfert de fichier
    depuis le serveur d'hébergement vers les conteneurs.</para>

    <para>Liste des actions à réaliser sur tous les conteneurs
    actifs.</para>
    <orderedlist>
    <listitem>
    <para>Installer le paquet <application>netplan.io</application></para>
    </listitem>
    <listitem>
    <para>Générer le fichier de déclaration <acronym>YAML</acronym> des
    paramètres de configuration réseau des interfaces
    <systemitem>eth0</systemitem></para>
    </listitem>
    <listitem>
    <para>Transférer le fichier de déclaration <acronym>YAML</acronym> dans le
    dossier <filename class='directory'>/etc/netplan/</filename></para>
    </listitem>
    <listitem>
    <para>Effacer le fichier
    <filename>/etc/systemd/network/eth0.network</filename></para>
    </listitem>
    <listitem>
    <para>Appliquer la nouvelle configuration réseau</para>
    </listitem>
    </orderedlist>
    </question>
    <answer>
    <para>Pour connaître les paramètres de configuration réseau d'une interface
    de conteneur, on peut extraire le fichier
    <filename>/etc/systemd/network/eth0.network</filename> et consulter son
    contenu.</para>

<screen>incus file pull c0/etc/systemd/network/eth0.network .
cat eth0.network</screen>

<screen>[Match]
Name=eth0

[Network]
DHCP=true

[DHCPv4]
UseDomains=true

[DHCP]
ClientIdentifier=mac</screen>

    <para>On vérifie ainsi que la configuration réseau issue de la source de
    tirage des conteneurs implique un adressage automatique au moins en
    <acronym>IPv4</acronym>. On propose donc de remplacer cet adressage
    automatique par un adressage statique.</para>

    <para>Proposition de script qui traite chacun des points définis
    dans la question.</para>

<screen>#!/bin/bash

# Préparation -> générer la liste des conteneurs actifs
clist=$(incus list status=running -c n -f compact | grep -v NAME | tr '\n' ' ' | tr -s ' ')

# Étape 1 -> installer le paquet netplan.io
. run-commands-in-containers.sh "apt -y install netplan.io"

addr_idx=0
for c in $clist; do
  echo ">>>>>>>>>>>>>>>>> $c"

# Étape 2 -> générer le fichier de configuration réseau YAML
$(cat &lt;&lt; EOF > eth0.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      dhcp4: false
      dhcp6: false
      accept-ra: true
      addresses:
        - 192.0.2.$((addr_idx + 10))/24
        - fda0:7a62:1b8::$(printf "%x" $((addr_idx + 10)))/64
      routes:
        - to: default
          via: 192.0.2.1
        - to: "::/0"
          via: fe80::baad:caff:fefe:5
          on-link: true
      nameservers:
        addresses:
          - 172.16.0.2
          - 2001:678:3fc:3::2
EOF
)

# Étape 3 -> transférer le fichier de déclaration YAML
  incus file push eth0.yaml $c/etc/netplan/eth0.yaml

# Étape 4 -> effacer le fichier /etc/systemd/network/eth0.network
  incus exec $c -- rm /etc/systemd/network/eth0.network

# Étape 5 -> appliquer la nouvelle configuration
  incus exec $c -- netplan apply

  ((addr_idx++))
done

exit 0</screen>

    <para>Si le code du script ci-dessus est placé dans un fichier appelé
    <filename>set-static-addressing.sh</filename>, on peut l'exécuter
    directement et relever les résultats.</para>

<screen>bash set-static-addressing.sh</screen>
<screen>incus restart --all</screen>

<screen>incus ls
+------+---------+-------------------+-------------------------------------------+-----------+-----------+
| NAME |  STATE  |       IPV4        |                   IPV6                    |   TYPE    | SNAPSHOTS |
+------+---------+-------------------+-------------------------------------------+-----------+-----------+
| c0   | RUNNING | 192.0.2.10 (eth0) | fda0:7a62:1b8::a (eth0)                   | CONTAINER | 0         |
|      |         |                   | fda0:7a62:1b8:0:216:3eff:febd:a233 (eth0) |           |           |
+------+---------+-------------------+-------------------------------------------+-----------+-----------+
| c1   | RUNNING | 192.0.2.11 (eth0) | fda0:7a62:1b8::b (eth0)                   | CONTAINER | 0         |
|      |         |                   | fda0:7a62:1b8:0:216:3eff:fe8e:cc62 (eth0) |           |           |
+------+---------+-------------------+-------------------------------------------+-----------+-----------+
| c2   | RUNNING | 192.0.2.12 (eth0) | fda0:7a62:1b8::c (eth0)                   | CONTAINER | 0         |
|      |         |                   | fda0:7a62:1b8:0:216:3eff:fe7d:6898 (eth0) |           |           |
+------+---------+-------------------+-------------------------------------------+-----------+-----------+</screen>
    </answer>
    </qandaentry>
    </qandaset>
    </sect2>
</sect1>

<sect1 xml:id='inter-vlan-iaas.conclusion'>
    <title>Pour conclure</title>

    <para>Le routage inter-VLAN est une composante essentielle des
    environnements virtualisés et des réseaux hybrides qui connectent le monde
    physique au cloud. Il permet de segmenter logiquement les infrastructures
    complexes, ce qui garantit une plus grande flexibilité et sécurité.</para>

    <para>La gestion des conteneurs avec Incus se distingue par sa simplicité
    et sa souplesse. Le mode &url.macvlan; présenté ici offre une solution
    efficace pour isoler les conteneurs les uns des autres, avec un coût
    d'administration minimal.</para>

    <para>En matière d'automatisation, il est pertinent de privilégier des
    traitements «&nbsp;atomiques&nbsp;». Toutefois, l'utilisation de boucles
    complexes dans les scripts Bash peut être optimisée. Pour aller plus loin,
    il est essentiel de séparer clairement l'inventaire des équipements
    (routeurs, commutateurs, machines virtuelles et conteneurs) des procédures
    d'automatisation. Ce principe est fondamental pour une gestion
    efficace.</para>
</sect1>
</article>
